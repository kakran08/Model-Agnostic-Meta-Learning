{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Agnostic Meta learning (MAML)**"
      ],
      "metadata": {
        "id": "yjFrrWSk9lFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical formula for MAML can be expressed as follows:\n",
        "\n",
        "Given a set of tasks T = {T1, T2, …, TN}, where each task Ti has a training set Di, MAML aims to find a set of parameters θ that can be quickly adapted to new tasks.\n",
        "\n",
        "1. Initialization: Initialize the model parameters θ randomly or with pre-trained weights.\n",
        "\n",
        "2. Inner loop: For each task Ti, compute the adapted parameters θi by taking a few gradient steps on the loss function L(Di, θ) using the training data Di.\n",
        "\n",
        "3. Outer loop: Update the initial parameters θ by taking the gradient descent step on the meta-objective J(T, θ) over all tasks. This objective measures the performance of the adapted parameters θi on the validation set for each task. Different meta-objectives can be used, such as minimizing the average loss or maximizing the accuracy across tasks.\n",
        "\n",
        "4. Repeat steps 2 and 3 for a few iterations to refine the initial parameters.\n"
      ],
      "metadata": {
        "id": "5TCdPRrrEFM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install higher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqY4n7iMBQUn",
        "outputId": "a7fe00dc-4769-4e9c-8a67-684aaa68ceb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting higher\n",
            "  Downloading higher-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from higher) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->higher) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->higher)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->higher)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->higher)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->higher)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->higher)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->higher)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->higher)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->higher) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->higher) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->higher) (3.0.2)\n",
            "Downloading higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, higher\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed higher-0.2.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import higher  # for differentiable inner loop updates\n",
        "\n",
        "# ----- Define the Model -----\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# ----- Prepare the MNIST Dataset -----\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# For demonstration, use a smaller subset of MNIST as our \"meta-training\" pool.\n",
        "# In a real few-shot setup, you would create tasks based on classes and sample a support & query set.\n",
        "meta_train_indices = np.random.choice(len(mnist_train), 10000, replace=False)\n",
        "meta_train_dataset = Subset(mnist_train, meta_train_indices)\n",
        "\n",
        "# Create a DataLoader (we’ll sample tasks from it later)\n",
        "meta_train_loader = DataLoader(meta_train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# ----- Helper Function to Sample a Task -----\n",
        "def sample_task(dataset, support_size=32, query_size=32):\n",
        "    \"\"\"\n",
        "    Randomly sample support and query sets from the dataset.\n",
        "    \"\"\"\n",
        "    indices = np.random.choice(len(dataset), support_size + query_size, replace=False)\n",
        "    support_indices = indices[:support_size]\n",
        "    query_indices = indices[support_size:]\n",
        "\n",
        "    support_loader = DataLoader(Subset(dataset, support_indices), batch_size=support_size)\n",
        "    query_loader = DataLoader(Subset(dataset, query_indices), batch_size=query_size)\n",
        "\n",
        "    # Get one batch from each loader\n",
        "    support_images, support_labels = next(iter(support_loader))\n",
        "    query_images, query_labels = next(iter(query_loader))\n",
        "\n",
        "    return support_images, support_labels, query_images, query_labels\n",
        "\n",
        "# ----- MAML Inner Loop Step Using higher -----\n",
        "def maml_inner_loop(model, inner_optimizer, support_images, support_labels, inner_steps=2, inner_lr=0.01):\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    # Use higher to create a functional version of the model and optimizer state.\n",
        "    with higher.innerloop_ctx(model, inner_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
        "        # Perform inner loop adaptation on the support set.\n",
        "        for _ in range(inner_steps):\n",
        "            support_preds = fmodel(support_images)\n",
        "            support_loss = loss_fn(support_preds, support_labels)\n",
        "            diffopt.step(support_loss)\n",
        "        return fmodel  # returns the adapted model\n",
        "\n",
        "# ----- MAML Outer Loop (Meta-Training) -----\n",
        "def meta_train(model, meta_dataset, meta_optimizer, epochs=5, tasks_per_epoch=100,\n",
        "               support_size=32, query_size=32, inner_steps=1, inner_lr=0.01):\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        meta_loss = 0.0\n",
        "        for task in range(tasks_per_epoch):\n",
        "            # Sample a task: get support and query sets\n",
        "            support_images, support_labels, query_images, query_labels = sample_task(meta_dataset, support_size, query_size)\n",
        "\n",
        "            # Send data to device (CPU or GPU)\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            support_images = support_images.to(device)\n",
        "            support_labels = support_labels.to(device)\n",
        "            query_images = query_images.to(device)\n",
        "            query_labels = query_labels.to(device)\n",
        "            model.to(device)\n",
        "\n",
        "            # Create an inner optimizer for the adaptation (using the same initial model parameters)\n",
        "            inner_optimizer = optim.SGD(model.parameters(), lr=inner_lr)\n",
        "            # Get adapted model after inner loop updates\n",
        "            fmodel = maml_inner_loop(model, inner_optimizer, support_images, support_labels, inner_steps, inner_lr)\n",
        "\n",
        "            # Evaluate the adapted model on the query set\n",
        "            query_preds = fmodel(query_images)\n",
        "            query_loss = loss_fn(query_preds, query_labels)\n",
        "\n",
        "            # Accumulate the loss\n",
        "            meta_loss += query_loss\n",
        "\n",
        "        # Average loss over tasks\n",
        "        meta_loss /= tasks_per_epoch\n",
        "\n",
        "        # Meta-optimization step: update the original model parameters\n",
        "        meta_optimizer.zero_grad()\n",
        "        meta_loss.backward()\n",
        "        meta_optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Meta Loss: {meta_loss.item():.4f}\")\n",
        "\n",
        "# ----- Main Script -----\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize model and meta-optimizer\n",
        "    model = SimpleCNN(num_classes=10)\n",
        "    meta_optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Run meta-training\n",
        "    meta_train(model, meta_train_dataset, meta_optimizer, epochs=5, tasks_per_epoch=100,\n",
        "               support_size=32, query_size=32, inner_steps=1, inner_lr=0.01)\n",
        "\n",
        "    # After meta-training, you can adapt the model quickly to new tasks.\n",
        "    # For example, sample a new task and perform a few inner loop updates:\n",
        "    support_images, support_labels, query_images, query_labels = sample_task(meta_train_dataset)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    support_images, support_labels = support_images.to(device), support_labels.to(device)\n",
        "\n",
        "    # Create a new inner optimizer for adaptation\n",
        "    inner_optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    adapted_model = maml_inner_loop(model, inner_optimizer, support_images, support_labels, inner_steps=5, inner_lr=0.01)\n",
        "\n",
        "    # Evaluate the adapted model on the query set\n",
        "    query_images, query_labels = query_images.to(device), query_labels.to(device)\n",
        "    adapted_preds = adapted_model(query_images)\n",
        "    predicted_labels = torch.argmax(adapted_preds, dim=1)\n",
        "    print(\"Predicted labels after adaptation:\", predicted_labels.cpu().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72uTtCtbBL2n",
        "outputId": "43ef176f-1c86-45e7-8c2c-c7646d7cd3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Meta Loss: 2.3021\n",
            "Epoch 2/5, Meta Loss: 2.2693\n",
            "Epoch 3/5, Meta Loss: 2.2148\n",
            "Epoch 4/5, Meta Loss: 2.1454\n",
            "Epoch 5/5, Meta Loss: 2.0572\n",
            "Predicted labels after adaptation: [6 0 2 9 9 2 2 6 9 6 9 7 1 9 6 1 7 3 1 9 1 3 3 0 9 2 9 9 9 9 0 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQxajeDyBSjy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}